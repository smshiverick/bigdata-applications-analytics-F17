\documentclass[sigconf]{acmart}

\input{format/i523}

\begin{document}
\title{Using Machine Learning Classification of Opioid Addiction
for Big Data Health Analytics}

  \author{Sean M. Shiverick}
  \affiliation{%
  \institution{Indiana University Bloomington}
}
\email{smshiver@indiana.edu}

\renewcommand{\shortauthors}{S.M. Shiverick}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Classification of opioid addiction can identify important features relevant 
for predicting drug abuse and overdose death. Machine learning procedures were 
applied to data from a large National Survey of Drug Use and Health (NSDUH-2015) 
to classify individuals for illicit opioid use according to demographic 
characteristics and mental health attributes (e.g., depression). Classification 
models of opioid addiction can be extended for big data health analytics to 
include high-dimensional datasets, data collected over previous years, or 
expanded to the larger population of patients taking prescription opioid 
medication. The results seek to raise awareness of risk factors related to 
opioid addiction among patients and medication prescribers, and help 
decrease the risk of opioid overdose death. 
\end{abstract}

\keywords{Health Analytics, Machine Learning Classifiers, Opioid Addiction, 
Big Data, i523, hid335}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Big Data offers tremendous potential to fuel innovation and transform society. 
Can this momentum be harnessed to address a serious health crisis such as the 
opioid overdose epidemic? \cite{cdc16} Health informatics is generating huge 
amounts of data at a rapid pace, from electronic medical records (EMRs), 
clinical research data, to population-level public health data \cite{herland14}. 
This project considers health analytics from two levels, the research questions 
being addressed and the data used to answer them. The question of interest in 
this project is whether opioid dependency and addiction can be predicted from 
demographic attributes and psychological characteristics. Survey research 
provides data on a wide range of issues that people may be reluctant to 
disclose, including mental health disorders, personal medical health concerns, 
prescription medications, and illicit drug use. Responses to surveys may be 
biased to some degree, but measures of confidentiality and anonymity help to 
assure more accurate disclosures. The goal of this project is to use machine 
learning procedures to classify individuals susceptible to opioid abuse and 
dependence. Understanding the features that contribute to opioid addiction 
can identify underlying risk factors and increase awareness of potential 
opioid abuse for patients and health care providers. The results could be 
extended to big data from previous years of the opioid crisis and to the 
larger population of patients taking prescription opioid mediation. Different 
machine learning classification methods are discussed.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Opioid Overdose Epidemic}

The abuse of prescription opioid medication in the U.S. has become a major 
health crisis of epidemic proportions \cite{volkow14}. Over 2 million Americans 
were dependent or abused prescription opioids such as oxycodone or hydrocodone 
in 2014\cite{cdc17}. Overdose deaths from prescription opioids have quadrupled 
since 1999, resulting in more than 180,000 deaths between 1999 to 2015 
\cite{nida17}. Drug overdose deaths increased significantly for males and 
females, between 25-44 years, ages 55 and older, for Non-Hispanic Whites and 
Blacks, in the Northeast, Midwest, and Southern regions of the U.S.
\cite{cdc16}. Mobile health applications can monitor patient medication 
consumption and provide an early warning system for potential abuse, detecting 
sudden changes in medications, higher dosages, or rapid escalation of a 
prescribed dosage \cite{varshney13}. Reliable information about medication 
dosages can be difficult to obtain based on self-reports. Individuals dependent 
or addicted to prescription opioids may obtain synthetic opioids such as 
fentanyl or illicit drugs such as heroin. Because the dosage levels and potency 
of illicit opioids are largely unknown, there is greater risk of drug overdose 
death. The sharp increase in overdose deaths due to synthetic opioids (other 
than methadone) has coincided with the increased availability of illicitly
manufactured fentanyl, which is indistinguishable from prescription fentanyl. 
The findings indicate the opioid overdose epidemic is getting worse, and 
requires urgent action to prevent opioid dependence, abuse and overdose death. 
The target group for this project is individuals who reported misusing or 
abusing prescribed opioid medication who also used heroin, shown in Figure 1. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Machine Learning Approaches} 

Machine learning is a set of procedures and automated processes for extracting 
knowledge from data. The two main branches of machine learning are supervised 
learning and unsupervised learning. Supervised learning problems involve 
prediction about a specific target variable or outcome of interest. If a given 
dataset has no target outcome, unsupervised learning methods can be used to 
discover underlying structure in unlabeled data. The goal of this project is 
to classify opioid addiction and focuses on supervised learning. Supervised 
learning is used to predict a certain outcome from a given input, when examples 
of input/output pairs are available \cite{muller17}. A machine learning model 
is constructed from the training set of input-output pairs, to predict new test 
data not previously seen by the model. The two major approaches to supervised 
learning problems are regression and classification. When the target variable 
to be predicted is continuous, or there is continuity between the outcome 
(e.g., home values, or income), a regression model is used to test the set of 
features that predict the target variable. If the target is a class label, set 
of categorical or binary outcomes (e.g., `spam` or `ham`, `benign` or 
`malignant`), then classification is used to predict which class or category 
label that new instances will be assigned to.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classification Algorithms} 

Comparing the performance of different learning algorithms can be helpful for 
selecting the best model for a given problem \cite{raschka17}. One of the 
simplest classification algorithms is K-Nearest-Neighbors (KNN) which takes 
a set of data points and classifies a new data point based on the distance 
(e.g., Euclidean, by default) to its nearest neighbors. The main parameter for
KNN is the number of neighbors, and k of 3 or 5 neighbors works well. The 
advantage of the KNN classifier is that it provides a solution that is easy to 
understand. A limitation of KNN is that it does not perform well with a large 
number of features (100 or more) or sparse datasets. Several different 
classification algorithms are considered below.

\subsubsection{Logistic Regression Classifier}

Logistic regression is a commonly used linear model for classification problems. 
The decision boundary for the logistic regression classifier is a linear function 
of the input; a binary classifier separates two classes using along a line, 
plane, or hyperplane. Linear classification models differ in terms of (1) how 
they measure how well a particular combination of coefficients and intercept fit 
the training data, and (2) the type of regularization used \cite{muller17}. The 
main parameter for linear classification models is the regularization parameter 
`C`. High values of C correspond to less regularization and the model will fit 
the training set as best as possible, stressing the importance of each individual 
data point to be classified correctly. By contrast, with low values of C, the 
model puts more emphasis on finding coefficient vectors (w) that are close to 
zero, trying to adjust to the `majority` of data points \cite{muller17}. In 
addition, the penalty parameter influences the coefficient values of the linear 
model. The L2 penalty (Ridge) uses all available features, but pushes the 
coefficient values toward zero. The L1 penalty (Lasso) sets the coefficient 
values for most features to zero, and uses only a subset for improved
interpretability. This paper uses a logistic regression classifier to predict 
Heroin use from demographic attributes, mental health, prescription opioids, 
medication use, misuse, and illicit drug use. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Tree Based Models}

Decision tree models are widely used for classification and regression. Tree 
models ``learn'' a hierarchy of if-else questions that are represented in the
form of a decision tree. Building decision trees proceeds from a root node as 
the starting point and continues through a series of decisions or choices.
Each node in the tree either represents either a question or a terminal node 
(i.e.,leaf) that contains the outcome. Applied to a binary classification task, 
the decision tree algorithm ``learns'' the sequence of if-else questions that 
arrives at the outcome most quickly. For data with continuous features, the 
decisions are expressed in the form of, ``Is feature x larger than value y?''
\cite{muller17} In constructing the tree, the algorithm searches through all
possible decisions or tests, and find a solution that is most informative 
about the target outcome. A decision tree classifier is used for binary or 
categorical targets, and decision tree regression is used for continuous
target outcomes. The recursive branching process of tree based models yields
a binary tree of decisions, with each node representing a test that considers
a single feature. This process of recursive partitioning is repeated until
each leaf in the decision tree contains only a single target. Prediction for
a new data point proceeds by checking which region of the partition the 
point falls in, and predicting the majority in that feature space. The 
main advantage of tree based models is that they require little adjustment 
and are easy to interpret. A drawback is that they can lead to very complex
models that are highly overfit to the training data. A common strategy to 
prevent overfitting is \emph{pre-pruning}, which stops tree construction 
early by limiting the maximum depth of the tree, or the maximum number of 
leaves. One can also set the minimum number of points in a node required for 
splitting. Another approach is to build the tree and then remove or collapse 
nodes with little information, which is called \emph{post-pruning}. Decision
trees work well with features measured on very different scales, or with 
data that has a mix of binary and continuous features. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Random Forests Classifier}

A random forest is a collection of decision trees that are slightly different 
from the others, which each overfits the data in different ways. The idea 
behind random forests is that overfitting can be reduced by building many 
trees and averaging their results. This approach retains the predictive power 
of trees while reducing overfitting. Randomness is introduced into the tree 
building process in two ways: (a) selecting a bootstrap sample of the data, 
and (b) selecting features in each node branch \cite{muller17,raschka17}. In 
building the random forest, we first decide how many trees to build (e.g., 10 
or 100), and the algorithm makes different ransom choices so that each tree is 
distinct. The bootstrapping method repeatedly draws random samples of size n 
from the dataset (with replacement). The decision trees are build on these 
random samples that are the same size as the original data, with some points 
missing and some data points repeated. The algorithm also selects a random 
subset of p features, repeated separately each node in the tree, so that 
each decision at the node branch is made using a different subset of features.
These two processes help ensure that all of the decision trees in the random
forest are different. The important parameters for the random forests 
algorithm are the number of sampled data points and the maximum number of 
features; the algorithm could look at all of the features in the dataset
or a limited number. A high value for ``maximum features'' will produce 
trees in the random forest that are very similar and will fit the data 
easily based on the most distinctive features, whereas a low value will 
produce trees that are very different from each other, and reduces over-
fitting. Random forests is of the most widely used ML algorithms that works 
well without very much parameter tuning or scaling of data. A limitation of 
this approach is that Random forests do not perform well with very high-
dimensional, data that is sparse data, such as text data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Project Goals} 

The general idea of the project is that prescription opioid dependency and
addicted will in many cases lead to the use of illicit opioids such as heroin 
or fentanyl. According to this reasoning, it was hypothesized that individuals 
who report using heroin may also be susceptible to misusing or abusing 
prescription opioid medications. The goal of the study was to identify the set 
of features important for predicting opioid addiction. The data used in the 
project is from the National Survey on Drug Use and Health from 2015 (NSHUH-
2015) \cite{samhsa16}, which is the most recent year available. The NSDUH-2015 
is a comprehensive survey that covers all aspects of substance use, misuse, 
dependency, and abuse, including questions related to both prescription 
medications (opioids, tranquilizers, sedatives) and illicit drugs (e.g., 
heroin, cocaine, methamphetamine), drug dependency, addiction, and treatment, 
demographic measures of education and employment, physical health, depression, 
and mental health treatment. Several classification models were constructed to 
classify heroin use in the sample by demographics attributes and mental health 
characteristics (e.g., adult depression). This method addresses the following
issues related to opioid dependency and addiction: (i) Identify factors related 
to illicit opioid use, (ii) Identify factors related to prescription opioid 
misuse and abuse, and (iii) Examine the relationship between prescription 
opioid misuse, abuse and heroin use. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}

\subsection{Data} 

Data from the 2015 NSHUH was downloaded from the Substance Abuse and Mental 
Health Data Archive (SAMHDA) \cite{samhsa16} URL using the `get-data.py` 
function written to unzip the data files, extract the data as a Pandas data 
frame, and write the file to CSV file \cite{getdata17}. The dataset consists 
of 57,146 observations with 2,666 features representing individual-level 
responses from a survey of the U.S. population. According to the NSDUH 
codebook, sampling was weighted across states by population size for a 
representative distribution selected from 6,000 area segments. The sample 
design used five state sample size groups drawing more heavily from the eight 
states with the largest population (e.g., CA, FL, IL, MI, NY, OH, PA, TX) which 
together account for 48 percent of total U.S. population aged 12 or older. 
All identifying information was collapsed (e.g., age categories) and state 
identifiers were removed from the public use file to ensure confidentiality. 
The NSDUH public-use files do not include geographic location, or demographic 
variables related to ethnicity or immigration status. The weighted survey 
screening response rate was 81.94 percent and the weighted interview response 
rate was 71.2 percent. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Cleaning and Preparation }

\subsubsection{Data Cleaning}
All steps of this analysis was completed in a python interactive notebook 
\cite{data17} based following examples from \emph{Python for Data Analysis}
\cite{mckinney17}. After saving the NSDUH-2015 as a data frame object, the 
dataset was subset by columns to include demographic characteristics (e.g., 
age category, sex, marital status, education, employment status, and category 
of metropolitan area), measures of physical health (e.g., overall health, 
STDs, Hepatitis, HIV, Cancer, hospitalization), mental health (e.g., Adult 
Depression, Emotional Distress, Suicidal Thoughts, Plans), Suicide Attempts, 
Pain Reliever Medication Use, Misuse, and Abuse (over past year, past month), 
Prescription Opioid Medications Taken in Past year (e.g., Hydrocodone, 
Oxycodone, Tramadol, Morphine, Fentanyl, Oxymorphone, Demerol, Hydromorphone), 
Heroin Use, Abuse (over past year, past month), Tranquilizer Use, Sedative Use, 
Cocaine Use, Amphetamine and Methamphetamine Use, Hallucinogen Use, Drug 
Treatment (e.g., Inpatient, Outpatient, Hospital, Mental Health Clinic, ER, 
Drug Treatment Status), and Mental Health Treatment History. A codebook was 
created to provide a complete list of variables included with summaries 
of response categories \cite{codebook17}. The following steps were taken 
to detect and remove inconsistencies in the data \cite{rahm00}:
\begin{enumerate}
  \item Remove missing values (i.e., `NaN`) 
  \item Recode blanks, non-responses, or legitimate skips (e.g.,`99`, `991`, 
  `993`) to zero  
  \item Recode dichotomous responses (e.g., ``Yes=1``/``No=2``) so that ``No=0``
  \item Recode categorical variables to be consistent with amount or degree 
  (e.g., ``1=low``, ``2=med``, ``3=high``)
   \item Rename selected variables for better description (e.g., 
   Adult Major Depressive Episode Lifetime changed from `AMDELT` to `DEPMELT`)
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Aggregate Variables}

Because the majority of features were represented as dichotomous ``Yes/No`` 
variables, related features were summed to create aggregated variables. For 
example, overall health, STD, Hepatitis, HIV, Cancer, and hospitalization were 
aggregated to create a single health measure. The health measure was recoded
so that higher scores indicated better health. Questions related to depression, 
emotional distress, and suicidal thoughts were summed to create a single 
variable for mental health (`MENTHLTH`) with scores ranging from 0 to 9. 
Responses to pain reliever medication use, misuse, abuse, or dependency, 
were aggregated to create a single variable of pain reliever misuse or abuse
(`PRLMISAB`). All prescription painkiller medications used in the past year
were summed. Similarly, all related responses were summed to create single 
variables for Tranquilizers, Sedatives, Cocaine, Amphetamines, Hallucinogens, 
Drug Treatment, and Mental Health Treatment. The target outcome of interest for 
classification, lifetime heroin use (i.e., ``Have you ever used heroin before, 
at any time?'') is a dichotomous variables. The demographic characteristics 
and aggregated variables were subset and saved to a new data frame consisting 
of 2 features and 57,146 observations, which was exported to CSV file. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

\subsection{Exploratory Data Analysis}

Of the total sample of N=57,146 respondents, 26,736 were male and 30,410 
female; 6,343 individuals reported misusing pain medication at some point; 
however, only 956 repondents had used heroin (570 males, 386 females). Table 1 
shows the raw counts of individual substance use by age group (with the sample 
size for each age group), listing the ten most commonly used opioid pain 
medications, self-reported misuse of prescription opioid pain relievers (i.e., 
PRL Misuse Ever), use of prescription Tranquilizers, Sedatives, and Methadone. 
In addition, self-reported use of illicit drugs such as heroin, cocaine, 
amphetamines, methamphetamine, Hallucinogens, including LSD and Ecstasy 
(MDMA). This summary table shows that substance use seems to be highest for 
individuals between the ages of 18 to 25 and from 35 to 49 years. Of the
prescription relievers, Hydrocodone use was almost double the rate of 
Oxycodone use for each age group, and was significantly higher than any other 
prescription opioid medication. Use of prescription Fentanyl and Demerol,
two powerful opioids, and synthetic morphines such as Oxymorphone and
Hydromorphone, was very low. The rate of prescription Tranquilizer use
was several orders of magnitude higher than Sedative use or Methadone use.
Compared to other illicit drugs such as Cocaine, Amphetamines, Hallucinogens,
heroin use was not very common in this sample. The highest rates of heroin
use were seen between the ages of 18 to 49, and was lowest for respondents
in the youngest age group 12 to 17, and individuals over 50. 

\begin{table}
  \caption{Substance Use by Age Group Counts - NSDUH 2015
  \cite{samhsa16}}
  \label{tab:freq}
  \begin{tabular}{cccccc}
    \toprule
    Age Group & 12-17& 18-25& 26-34& 35-49& 50+\\
    \midrule
    Sample Size & 13585& 14553& 9084& 11169& 8755 \\
    \midrule
    Oxycodone& 545& 1632& 1132& 1345& 1044 \\
    Hydrocodone& 831& 2936& 2233& 2781& 2103 \\
    Tramadol& 241& 753& 654& 829& 734 \\
    Morphine& 251& 431& 236& 313& 286 \\
    Fentanyl& 28& 97& 81& 96& 86 \\
    Demerol& 26& 74& 49& 64& 71 \\
    Buprenorphine& 43& 197& 167& 124& 51 \\
    Oxymorphone& 46& 88& 57& 47& 41 \\
    Hydromorphone& 24& 94& 107& 118& 81 \\
    \midrule
    PRL Misuse Ever*& 798& 2127& 1475& 1343& 600 \\
    \midrule
    Tranquilizers& 405& 1469& 1064& 1405& 1153 \\
    Sedatives& 204& 242& 157& 256& 226 \\
    Methadone Ever& 32& 83& 96& 71& 46 \\
    \midrule
    Heroin Use Ever*& 22& 261& 259& 250& 164 \\
    \midrule
    Cocaine Use Ever& 109& 1645& 1626& 1954& 1406 \\
    Amphetamines Ever& 932& 1836& 627& 383& 164 \\
    Methamphetamine& 42& 481& 700&  898& 492 \\
    Hallucinogens& 450& 2660& 2020& 2127& 1197 \\
    LSD Use Ever& 190& 1114& 874& 1442& 907 \\
    Ecstasy (MDMA)& 199& 1867& 1403& 947& 149 \\
    \bottomrule
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Table 2 shows the frequency of individuals reporting that they had experienced
mental health issues such as depression, suicidal thoughts,whether they had 
received mental health treatment, received treatment from a private therapist, 
or believed that they needed drug treatment, but had not sought treatment, 
across each age category. Frequency of depression was not included for 
respondents between 12 to 17 years, and the measure was of adult depression. 

\begin{table}
  \caption{Frequency Table of Mental Health Issues and Treatment NSDUH 2015
  \cite{samhsa16}}
  \label{tab:freq}
  \begin{tabular}{cccccc}
    \toprule
    Age Group & 12-17& 18-25& 26-34& 35-49& 50+\\
    \midrule
    In Hospital Overnight& 730& 1149& 821& 890& 1173 \\
    Adult Depression& 0& 2413& 1395& 1766& 967 \\
    Suicidal Thoughts& 13585& 14553& 9084& 11189& 8755 \\
    \midrule
    Mental Health Treatment& & & & & \\
    \midrule
    Private Therapist& 0& 592& 434& 554& 311 \\
    Treatment Gap*& 469& 931& 321& 239& 90 \\
    \bottomrule
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Figure 1 shows the proportion of individuals who reported misusing prescription 
opioid pain relievers and who reported using heroin. The left column of the 
Figure 1 shows the majority of respondents (89 percent) stated they had never 
misused prescription opioid pain medication or used heroin, although 10 percent 
reported misusing opioid pain medication at some point. The right panel of 
Figure 1 shows that, of those individuals who reported using heroin, the 
proportion who also reported misusing opioid pain medication was almost twice 
as large as the proportion of those who only used heroin. This is consistent 
with the hypothesis that misuse of prescription opioids is linked with heroin 
use for some individuals.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure1.pdf}
  \caption{Proportion of Individuals Who Reported Ever Misusing Prescription
  Opioid Pain Relievers and Proportion Who Reported Using Heroin}
  \label{f:Figure1}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Figure 2 shows the aggregated measure of Opioid Pain Reliever misuse and abuse 
plotted against the aggregated measure of Heroin use (which includes misuse, 
abuse, lifetime use, past year use, 30 day use), with weighted regression 
lines grouped by size of City Metropolitan region (from none to large). 
The largest proportion of the sample who report prescription opioid misuse, 
abuse, and heroin use is represented by observations from large metropolitan 
areas (red circles) with large population size. However, a small number of
observations from rural or small metropolitan regions (blue and green circles)
showed very high rates of prescription opioid misuse and abuse. Regression 
lines (i.e., line of best fit) shown are weighted by the City/Metro
region attribute, with a steeper slope shown for smaller metropolitan regions 
than large metropolitan regions. The difference in slope may be due to the 
influence of the small number of outliers who had high degrees of prescription 
opioid misuse, and heroin use. The plot also shows a clear divide on the y-axis,
which separates the sample according to high and low or no prescription opioid 
misuse, although the continuum of heroin use from no, low, to high is 
distributed fairly evenly along the x-axis. 


\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure2.pdf}
  \caption{Plot of Opioid Pain Medication Misuse and Abuse and Heroin Use
  with Regression Slopes Weighted by Metropolitan Area Size}
  \label{f:Figure2}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Figure 3 shows the pairplots of demographic features including mental health
(higher scores equal to more depression), Prescription Opioid Pain Reliever
(PRL) Medication (aggregated), Heroin Use (aggregated measure), and Size of 
City/Metropolitan region. The top row shows that the majority of the sample 
reported no mental health concerns, whereas a small proportion of the sample 
reported depression, emotional distress, or suicidal thoughts. Only few people 
self-described as high in depression reported low Prescription Opioid PRL 
misuse and abuse. The plot also reveals that prescription opioid misuse and 
heroin use were distributed approximately evenly for individuals reporting 
either low, moderate, or high levels of depression, which suggests that 
depression was not a factor in predicting opioid misuse. The second row shows 
a small number of individuals from rural areas or small cities who reported 
very high levels of prescription opioid misuse, although the majority of 
respondents misusing or abusing prescription opioid were from large 
metropolitan areas. As described above, the majority of respondents (about
90 percent of the sample) reported they had never misused prescription 
opioids. In the second row and third and fourth columns, a natural break is 
seen between individuals who reported high levels of prescription opioid 
misuse and abuse and those who reported very low or no opioid misuse. A very 
small proportion of the entire sample reported both misusing and abusing 
prescription opioids and using heroin, but this is a group of interest. The 
last column of the second row shows the individuals reporting high levels of 
opioid misuse and abuse were distributed evenly across city/metropolitan areas 
of different sizes, with only slightly higher numbers for small cities or 
rural areas. As stated above, only few participants reported using heroin, and 
of these, the majority were from large metropolitan areas. Finally, the sample 
seems to have slightly higher proportions from small and large metropolitan 
areas, which is likely due to weighted sampling, which drew more from heavily 
populated regions.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure3.pdf}
  \caption{Pairplots of Mental Health, Prescription Opioid Misuse and Abuse,
  Heroin Use, and Size of City Metropolitan Area}
  \label{f:Figure3}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classifier Models of Heroin Use}

This analysis classified individuals according to whether they had ever used 
heroin (i.e., ``Heroin Use Ever``). All classifier models were constructed 
using SciKit Learn \cite{muller17} using an interactive python jupyter 
notebook \cite{classifyH}. The features of interest were demographic 
characteristics, health, mental health (adultdepression), prescription 
opioid misuse and abuse (`PRLMISEVR`, `PRLMISAB`, `PRLANY`), prescription 
tranquilizers and sedatives (`TRQLZRS`, `SEDATVS`), illicit drugs (`COCAINE`, 
`AMPHETMN`), drug treatment (`TRTMENT`), and mental health treatment 
(`MHTRTMT`). The target variable was Heroin Use (`HEROINEVR`). Next, the 
dataset was split into the training set and test sets using the `train-test
-split` function in `sklearn`. Model accuracy for the training set and test 
set are reported, with different parameter values, and features importance. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Logistic Regression Classifier}
 
Logistic Regression Classification is a based on a linear equation that 
calculates the relative weight of each feature for a categorical target or 
binary outcome (``yes/no``)\cite{raschka17}. The logistic regression classifier 
was fit to the training data in Scikit-Learn, and the model was validated on 
the test data. By default, the model applies L2 penalty (Ridge). The training 
set accuracy was 0.983 and the test set accuracy was 0.984. The parameter `C` 
determines the strength of regularization, with higher values of C providing
greater regularization. The L1 penalty (Lasso) limits the values of most 
coefficients to zero, creating a more interpretable model that uses only a 
few features. Figure 4 plots the coefficients of logistic regression classifier 
for heroin use with the L1 Penalty (Lasso) under different values of parameter 
C. The default setting, C=1.0, provides good performance for train and test 
sets, but the model is very likely underfitting the test data. Using a higher
value of C fits a more 'flexible' model and generally gives improved accuracy 
for both training and tests sets. Using a value of C=100 yielded training set
accuracy of 0.98 and test set accuracy of 0.98. Figure 4 shows that the 
features coefficient values did not change much according to the values of
parameter C, and the accuracy values were approximately the same for all 
values of C. Examination of the coefficients from the logistic regression 
classifier revealed the three features which were most closely associated 
with Heroin use were: Prescription Opioid Pain Reliever (PRL) Misuse ever 
(as predicted), Cocaine Use, and Amphetamine use, respectively.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure4.pdf}
  \caption{Coefficients of Logistic Regression Classifier of Heroin Use 
  (With L1 Penalty and Values of Regularization Parameter C)}
  \label{f:Figure4}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Decision Tree Classifier}

The following analysis used the \emph{Decision Tree Classifier} package in 
Scikit-Learn, which only does pre-pruning. First, the decision model was build
using the default setting of a fully developed tree until all leaves are pure. 
The random state` features is fixed to break ties internally. Accuracy on the
training set was 0.99 and test set accuracy was 0.974. Without restricting 
their depth, decision trees can become complex; unpruned trees are prone to 
overfitting and do not generalize well to new data. Limiting the depth of 
tree decreases overfitting, which results in lower training set accuracy, 
but improved performance on the test set. Next, pre-pruning was applied, with 
a maximum depth of 4, which means the algorithm split on four consecutive
questions. Training set accuracy of the pruned tree was 0.985 and test set
accuracy was 0.984. Even with a depth of 4, the tree can become a bit complex.
Figure 5 shows a partial view of the decision tree classifier of heroin use 
(the entire tree was too wide to include as a legible Figure), and the full 
tree image is available in the notebook `BDA-Analytics-Classifier-Heroin.ipynb` 
\cite{classifyH}. The decision tree shows the top features that the algorithm 
split on to classify heroin use. One way to interpret a decision tree it by 
following the sample numbers represented at the test split for each node. 
The classifier algorithm selected Cocaine Use (aggregated score) as the root 
node of the decision tree. The branch to the left  side of the tree represents 
samples with a score equal to or less than 1.5 (n=40956), whereas the branch 
to the right represents samples with a Cocaine Use score greater than 1.5
(n=1903). The second split on the right occurs for Any Prescription Opioid 
Pain Reliever Use (`PRLANY`), with n=1443 having a score less than or equal 
to 3.5, and n=460 respondents with a PRL score greater than 3.5. In other 
words, of those respondents who reported relatively high Cocaine use, a small
portion also reported relatively high Prescription Opioid PRL use. Instead of 
looking at the whole tree, features importance is a common summary function 
that rates how important each feature is for the classification decisions 
made in the algorithm. Each feature is assigned an importance value between 
0 and 1; with a value of 1 indicating the feature perfectly predicts the 
target and a value of 0 meaning that the feature was not used at all. 
Feature importance values also always sum to 1. A feature may have a low 
feature importance value because another feature encodes the same information. 
The top two important features for classifying Heroin Use were Cocaine Use 
and Any Prescription Opioid PRL Use, with smaller importance given to Opioid 
PRL Misuse Ever and Prescription Opioid PRL Misuse and Abuse. 

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure5.pdf}
  \caption{Decision Tree Classification of Heroin Use (Partial View)}
  \label{f:Figure5}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Random Forests Classifier}

Random forests is an ensemble approach that builds many trees and averages 
their results to reduce overfitting. The model was build using the Random 
Forest Classifier package in Scikit-Learn. The parameters of interest for
builiding random forests are: (a) the number of trees (`n-estimators`), 
(b) the number of data points for bootstrap sampling (`n-samples`), and 
(c) the maximum number of features considered at each node (`max-features`). 
The max-features parameter determines how random each tree is, with smaller 
values of max-features resulting in trees in the random forest that are very 
different from each other. This analysis applied a random forest consisting
of 100 trees to classify Heroin Use, and the random state was set to zero. 
The training set accuracy was 0.999 and the test set accuracy was 0.984. 
Often the default settings for random forests work well, but we can apply
pre-pruning as with a single tree, or adjust the maximum number of features. 
Feature importance for random forests is computed by aggregating the feature 
importance over trees in the random forest, and random forests gives
non-zero importance to more features than a single tree. Typically random
forests provide a more reliable measure of feature importance than the
feature importance for a single tree. Figure 6 shows the feature importance 
of the random forests classifier for heroin use with 100 trees. Similar to
the single tree, the random forest selected Cocaine Use as the most
informative feature in the model, followed by Any PRL Use, which is an 
aggregated measure of prescription opioid medication use. Following after 
that, several features were tied for third place of importance, namely 
Education Level, Overall Health, Age Category, and Pain Reliever Misuse 
and Abuse. Random forests provides much of the same benefit as decision
trees, while compensating for some of their shortcomings of overfitting.
Single trees are still useful for visually representing the decision process.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure6.pdf}
  \caption{Feature Importance for Random Forests Classifier for Heroin Use}
  \label{f:Figure6}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Gradient Boosting Classifier Tree}

Gradient boosting machines is another ensemble method that combines multiple
decision trees for regression or classification by building trees in a serial 
fashion, where each tree tries to correct for mistakes of the previous one
\cite{muller17}. Gradient boosted regression trees use strong pre-pruning, 
with shallow trees of a depth of one to five. Each tree only provides a good
estimate of part of the data, but combining many shallow trees (i.e., ``weak 
learners''), the use many simple models iteratively improves performance. In 
addition to pre-pruning and the number of trees, an important parameter for 
gradient boosting is the learning rate, which determines how strongly each
tree tries to correct for mistakes of previous trees. A high learning rate
produces stronger corrections, allowing for more complex models. Adding
more trees to the ensemble also increases model complexity. Gradient boosting
and random forests perform well on similar tasks and data; it is common to
first try random forests and then include gradient boosting to attain 
improvements in accuracy of the learning model. This analysis used the 
Gradient Boosting Classifier from Scikit-Learn to classify Heroin Use, with 
the default setting of 100 trees of maximum depth of 3, and a learning rate 
of 0.1. The model was build on the training set and evaluated on the test set, 
with both training set and test set accuracy equal to 0.984. To reduce
overfitting, pre-pruning could be implemented by reducing the maximum depth, 
or by reducing the learning rate. Figure 7 shows that the feature importance 
for the gradient boosting classifier tree looks similar to the feature 
importance for random forests, but the gradient boosting has decreased the 
importance of many features to zero. Again Cocaine is selected as the most 
imformative features, followed by Any Opioid PRL Use. In addition to 
Prescription Opioid PRL Misuse and Abuse, the gradient boosting classifier 
selected Amphetamine Use as an informative feature of Heroin Use. 

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure7.pdf}
  \caption{Feature Importance for Gradient Boosting Classifier for Heroin Use}
  \label{f:Figure7}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classifier Models of Prescription Opioid Pain Reliever (PRL) Misuse}

This section reports results from the same set of classification analyses
described above using Prescription Opioid Pain Reliever Misuse (`PRLMISEVR`) 
the target variable. Attributes related to Heroin Use were now included as
features (e.g., `HEROINEVR`, `HEROINUSE`, `HEROINFQY`). The classifier models 
were built using SciKit Learn in a python notebook \cite{classifyPRL}. The
dataset was split into the training set and test sets using the `train-test-
split` function in sklearn and the target variables was designated. Model
accuracy for the training set and test set are reported, for different 
parameter values, with feature importance. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Logistic Regression Classifier}

The logistic regression classifier was fit to the training data using the 
L1 penalty (Lasso), using different values of the regularization parameter C,
and the model was validated on the test data. Higher value of parameter C 
typically gives improved accuracy for both training and tests sets; however, 
in this case, the training set accuracy was 0.901 and test set accuracy was 
0.903, and these values were consistent for all values of parameter C. 
Figure 8 plots the coefficients of logistic regression classifier for 
Prescription Opioid PRL Misuse under different values of C. As shown in 
Figure 8, the features with the highest coefficient values were Treatment
(for substance use), Heroin Use (as predicted), as well as Cocaine and 
Amphetamine use. This result indicates that Prescription Opioid Misuse is 
positively related to Drug Treatment, meaning that respondents who reported
higher levels of opioids misuse were also in treatment, but that people 
who were misusing opioid medications were also more likely to have used
illicit drugs such as heroin, cocaine, and amphetamine. 

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure8.pdf}
  \caption{Logistic Regression Classification of Prescription Opioid 
  (PRL) Misuse
  with L2 Penalty}
  \label{f:Figure8}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Decision Tree Classifier}

The Decision Tree Classifier package in Scikit-Learn was used to build the 
tree model, pre-pruning was applied with a maximum depth of 4, which means 
the algorithm split on four consecutive questions. The training set accuracy 
of the pruned tree was 0.902 and test set accuracy was 0.902. Figure 9 shows 
a partial view of the decision tree classifier of prescription opioid misuse
(the full tree is included in the `BDA-Analytics-Classifier-PRL.ipynb` 
notebook) \cite{classifyPRL}. As Figure 9 shows, the decicion tree classifier
selected Cocaine Use as the root note, that branched by the test score equal
to or less than 0.5 (any Cocaine Use). At the second node, on the branch to 
the right n=5015 samples were further divided according to heroin use, with 
n=1913 having a score greater than 0.5 (any Heroin Use). At the third node
on the right branch, samples were selected according to Tranquilizer
medication use, with n=1419 scoring positively. On the left branch, the 
second node selected was Drug Treatment, with n=2844 respondents scoring
positively that they had received Drug Treatment. Feature importance of
the decision tree classifier selected Cocaine Use as the most informative
feature for Prescription Opioid PRL Misuse. Following afterwards, 
Tranquilizer Use, Drug Treatment, and Heroin Use were tied for second place. 

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure9.pdf}
  \caption{Decision Tree for Prescription Opioid (PRL) Misuse}
  \label{f:Figure9}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Random Forests Classifier}

The Random Forest Classifier package in Scikit-Learn was used to classify
Prescription Opioid PRL Misuse as the target variable, with 100 trees. The 
model accuracy for the training set was 0.955 and the test set accuracy was 
0.896, which suggests that the model overfit the data. Figure 10 shows the 
feature importance of the random forests classifier for Prescription Opioid 
PRL Misuse. As Figure 10 shows, several features were identified as important
for classifying Prescription Opioid PRL Misuse. The random forest selected 
Overall Health as the most informative feature in the model, followed by 
Cocaine Use, Education Level, Age Category, and Size of City Metropolitan 
region. Because of the additional features included as important, gradient boosting was performed to clarify the feature importance.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure10.pdf}
  \caption{Feature Importance for Random Forest Classifier of 
  Prescription Opioid (PRL) Misuse}
  \label{f:Figure10}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Boosted Gradient Classifier}

The Gradient Boosting Classifier from Scikit-Learn was used to classify 
Prescription Opioid PRL Misuse, using the default setting of 100 trees, of 
maximum depth of 3, and a learning rate of 0.1. The model accuracy for the
training set was 0.894 and accuracy for the test set was 0.893. Gradient 
boosting typically improves test set accuracy by using many simple models 
iteratively. In this case, model accuracy for gradient boosting was no better 
than random forests, and this is because the default parameter settings were
used; further parameter tuning is needed to improve model performance. Feature 
importance was a primary interest for identifying features related to '
prescription opioid abuse. Figure 11 shows the feature importance for the 
gradient boosting classifier tree. As Figure 11 shows, several features were 
important for classifying prescription opioid misuse, and contrary to the 
random forests, gradient boosting selected Tranquilizer use as the most 
informative feature. Following closely in importance were Heroin Use and Age 
Category. Tied for fourth place were Cocaine Use and Treatment, with Mental 
Health (depression) coming in fourth in terms of feature importance. This 
result illustrates that several features are important for understanding 
Prescription Opioid Misuse, and the relations among features may be complex.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure11.pdf}
  \caption{Feature Importance for Gradient Boosted Classifier Tree of 
  Prescription Opioid (PRL) Misuse}
  \label{f:Figure11}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

\subsection{Summary of Findings}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Extension to Big Data}

The methods used in this project could be extended to better approximate 
big data for health analytics in the following ways: (1) Include a larger 
selection of features from the 2600 attributes in in the NSDUH-2015 dataset; 
(2) Include survey data from previous years (e.g., 2005-2015); and (3) 
Extend the sample to the population of patients who have been prescribed 
opioid pain medication. There were many additional features that could have
been included in the subset of features included in the project dataset. 
However, data cleaning and preparation can be a time consuming process, 
especially for datasets with a large number of features \cite{rahm00}. 
Additional data from the NSDUH was downloaded from previous years (2012 to 
2014), and a preliminary examination of the data revealed inconsistencies 
in questions and prescription opioid medications that would need to be 
resolved in order to combine data from multiple years. In addition to data 
cleaning, there are several steps involved in the consolidation of data from 
multiple sources into a single dataset, which include extraction, integration, 
and aggregation of features. Unfortunately, time constraints for the project 
deadline did not allow for the inclusion of data from previous years into this 
analysis. A future study could integrate data from different years into the
analysis or include data from multiple sources. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Limitations}

To be of any use, diverse and often messy raw data has to be sifted through and 
effectively organized for further analysis, and 

there are legitimate questions about the reliability of self report data from 
surveyresearch for predicting actual behavior. 

The question of Value evaluates the quality of the data as it pertains to 
intended outcomes, such as limiting the spread of contagion and disease 
prevention. 

An important challenge for making sense of big data is developing analytic 
tools adequate to handle large volumes of data in real time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Drug Abuse, Dependency, and Addiction}

Drug addiction has many similar characteristics to other chronic medical 
illnesses, but there are unique challenges to the treatment of addiction
\cite{marsch12, swendson16}. In drug rehabilitation treatment programs, 
patients undergo intense detoxification that reduces their drug tolerance, but 
are then released back into the environments associated with their drug use, 
putting them at high risk for relapse and potential drug overdose 
\cite{johnson11}. According to a classical conditioning model of addiction, 
situational cues or events can elicit a motivational state underlying relapse 
to drug use. Addictive behavior can be also be reinstated after extinction of 
dependency by exposure to drug-related cues or stressors in the environment 
\cite{shaham03}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dynamics of Epidemic Spreading}

If the prescription opioid crisis is a guenuine epidemic, then we can conceive 
of it in terms of the dynamics of epidemic spreading which have been developed 
based on models of contagious disease. Epidemic spreading is a dynamic process 
based on networks of direct person-to-person contact and indirect exposure via
transportation pathways \cite{Colizza06}, that facilitate the distribution of 
opioid medications or illicit drugs. Instead of thinking about persons as
infected or uninfected by biological contagion, in the opioid drug model, we 
must consider individuals as dependent, addicted or susceptible to dependence
and addiction. Epidemics are quantified in terms of the proportion of the 
population infected, those yet to be infected, and the rate of transmission. 
Furthermore, the structure of the contact network can influence epidemic 
spreading \cite{pastor01}. For example, in the case of simple contagion, weak 
ties among acquaintances or infrequent associations provide shortcuts between 
distant nodes that reduce distance within the network \cite{granovetter73} 
which can facilitate the spread of contagion, or in this case drug use. 
Furthermore, opioid contact networks may have ``small world'' properties 
where a small number of nodes or people have a very number of connection
that can rapidly transmit contagion throughout the network \cite{watts98}. 
It may be possible to apply network analysis to identify underlying structure 
of the contact network of opioid use and addiction, to identify pathways and 
points of contact between nodes or person in the spreading use, misuse, and
abuse of prescription opioid medications. Future research could apply social 
network modeling to the opioid crisis in order to identify how drug dependancy 
and addiction are subserved by patterns of social interaction. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

Several machine learning methods were used to classify heroin use and 
prescription opioid misuse and abuse. The results of this analysis are somewhat inconclusive, given that the direction of these effect is unknown. On the one 
hand there is evidence that individual who reported having used heroin were 
also more likely to report misusing or abusing prescription opioids. On the 
other hand, the proportion of individuals who misused or abused prescription 
opioids, and also reported using heroin, was twice as large as the proportion 
who reported only using heroin. A general conclusion is that the results 
provide partial support for the hypothesis that taking prescription opioids
leads to a higher likelihood of illicid opioid use. However, the results did
not provide sufficienbt evidence to rule out the alternative hypothesis that
people who have used heroin may have a propensity for opioid use therefore
be more likely to become dependent on prescription opioid medications. Given
that the number of individuals who reported using heroin in this sample was
low, additional data may help to provide evidence to resolve this question.
A limitation of survey data is there may be bias in self-reports of illicit
drug use, as it is a proscribed and illegal behavior, and therefore the 
data may underestimate the actual rate of heroin use in the general population. 
Including additional data from previous years may provide a more tests of 
these hypotheses. 


Machine of opioid abuse can contribute to efforts to 
address prescription opioid addiction, overdoses, in the following ways: 
\begin{enumerate}
\item Identify factors related to opioid dependency
\item Inform consumers of opioid medication as to risk factors 
\item Increase knowledge of opioid abuse for more informed prescriptions. 
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{acks}

The author would like to thank Dr. Gregor von Laszewski, the Teaching 
Assistants, Juliette Zurick, Miao Jiang, Hungri Lee, Grace Li, Saber Sheybani
Moghadam, and others who helped to improve this project and report.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

\section{Code References}
All code, notebooks, files, and folders for this project can be found in the
i523/hid335/project githup repository: 
\url{url:  https://github.com/bigdata-i523/hid335/tree/master/project}.

\subsection{Download and Extract Data file}

The `get-data.py` function was written to download the data, unzip the data
files, extract the data, and write the NSDUH-2015 dataset to CSV file 
\cite{getdata17}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Cleaning and Preparation}

Data cleaning and preparation steps was conducted using an interactive python Jupyter Notebook \cite{data17} based on examples in Python for Data Analysis \cite{mckinney17} and the Python Data Science Handbook \cite{vanderplas17}.

\subsection{Exploratory Data Analysis}

Exploratory Data Analysis and Visualization was conducted using an interactive
python notebook: CITE URL

based on examples from Python for Data Analysis \cite{mckinney17}, and the 
Python Data Science Handbook \cite{vanderplas17}.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Machine Learning Classifier Algorithms}
Machine learning classification models included logistic regression classifier, 
decision Tree classifier, random forests classifier, and gradient boosting 
classifier were constructed using SciKit Learn \cite{muller17, raschka17} 
using two separate interactive python jupyter notebook, one for classifying 
Heroin Use as the target variable \cite{classifyH}, and another notebook for classifying Prescription Opioid Misuse as the target \cite{classifyPRL}. 


%\begin{enumerate}

%\item Do not to use the underscore in bibtex labels
%\item Address each of the items in the issues.tex file  
%item Please do this only at the end once you have finished writing the paper. 
%\item Change `TODO` with `DONE`. 

%\end{enumerate}

%\input{issues}

\end{document}
